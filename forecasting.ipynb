{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5006e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (888, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>producto_id</th>\n",
       "      <th>nombre</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>precio_base</th>\n",
       "      <th>es_estrella</th>\n",
       "      <th>unidades_vendidas</th>\n",
       "      <th>precio_venta</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>Decathlon</th>\n",
       "      <th>Deporvillage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Nike Air Zoom Pegasus 40</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>113.13</td>\n",
       "      <td>2941.38</td>\n",
       "      <td>89.51</td>\n",
       "      <td>113.43</td>\n",
       "      <td>104.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_002</td>\n",
       "      <td>Adidas Ultraboost 23</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>135</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>141.89</td>\n",
       "      <td>3831.03</td>\n",
       "      <td>128.73</td>\n",
       "      <td>112.91</td>\n",
       "      <td>122.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_003</td>\n",
       "      <td>Asics Gel Nimbus 25</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.79</td>\n",
       "      <td>428.95</td>\n",
       "      <td>84.28</td>\n",
       "      <td>74.51</td>\n",
       "      <td>85.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_004</td>\n",
       "      <td>New Balance Fresh Foam X 1080v12</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.19</td>\n",
       "      <td>228.57</td>\n",
       "      <td>75.54</td>\n",
       "      <td>70.32</td>\n",
       "      <td>71.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_005</td>\n",
       "      <td>Nike Dri-FIT Miler</td>\n",
       "      <td>Running</td>\n",
       "      <td>Ropa Running</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.48</td>\n",
       "      <td>106.44</td>\n",
       "      <td>33.84</td>\n",
       "      <td>31.32</td>\n",
       "      <td>34.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha producto_id                            nombre categoria  \\\n",
       "0  2025-10-25    PROD_001          Nike Air Zoom Pegasus 40   Running   \n",
       "1  2025-10-25    PROD_002              Adidas Ultraboost 23   Running   \n",
       "2  2025-10-25    PROD_003               Asics Gel Nimbus 25   Running   \n",
       "3  2025-10-25    PROD_004  New Balance Fresh Foam X 1080v12   Running   \n",
       "4  2025-10-25    PROD_005                Nike Dri-FIT Miler   Running   \n",
       "\n",
       "         subcategoria  precio_base  es_estrella  unidades_vendidas  \\\n",
       "0  Zapatillas Running          115         True               26.0   \n",
       "1  Zapatillas Running          135         True               27.0   \n",
       "2  Zapatillas Running           85        False                5.0   \n",
       "3  Zapatillas Running           75        False                3.0   \n",
       "4        Ropa Running           35        False                3.0   \n",
       "\n",
       "   precio_venta  ingresos  Amazon  Decathlon  Deporvillage  \n",
       "0        113.13   2941.38   89.51     113.43        104.78  \n",
       "1        141.89   3831.03  128.73     112.91        122.88  \n",
       "2         85.79    428.95   84.28      74.51         85.57  \n",
       "3         76.19    228.57   75.54      70.32         71.13  \n",
       "4         35.48    106.44   33.84      31.32         34.41  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar archivo de inferencia ventas_2025_inferencia.csv en un DataFrame\n",
    "from pathlib import Path\n",
    "inferencia_path = Path('..') / 'data' / 'raw' / 'inferencia' / 'ventas_2025_inferencia.csv'\n",
    "inferencia_df = pd.read_csv(inferencia_path)\n",
    "print('Shape:', inferencia_df.shape)\n",
    "inferencia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d4885c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ DataFrame transformado guardado en: ./data/processed/inferencia_df_transformado.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_9620\\3316482759.py:15: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  inferencia_df['es_festivo'] = inferencia_df['fecha'].isin(festivos_es).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# --- TRANSFORMACIÓN COMPLETA DE inferencia_df PARA INFERENCIA ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "\n",
    "# 1. Procesamiento de fechas\n",
    "inferencia_df['fecha'] = pd.to_datetime(inferencia_df['fecha'])\n",
    "inferencia_df['año'] = inferencia_df['fecha'].dt.year\n",
    "inferencia_df['mes'] = inferencia_df['fecha'].dt.month\n",
    "inferencia_df['dia_mes'] = inferencia_df['fecha'].dt.day\n",
    "inferencia_df['dia_semana'] = inferencia_df['fecha'].dt.day_name()\n",
    "inferencia_df['es_fin_semana'] = inferencia_df['dia_semana'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "festivos_es = holidays.country_holidays('ES', years=inferencia_df['fecha'].dt.year.unique())\n",
    "inferencia_df['es_festivo'] = inferencia_df['fecha'].isin(festivos_es).astype(int)\n",
    "\n",
    "# 2. Variables de ventas: lags y media móvil\n",
    "inferencia_df = inferencia_df.sort_values(['producto_id', 'fecha'])\n",
    "for lag in range(1, 8):\n",
    "    inferencia_df[f'unidades_vendidas_lag{lag}'] = inferencia_df.groupby('producto_id')['unidades_vendidas'].shift(lag)\n",
    "inferencia_df['unidades_vendidas_ma7'] = inferencia_df.groupby('producto_id')['unidades_vendidas'].shift(1).rolling(window=7).mean()\n",
    "\n",
    "# 3. Variables de precio\n",
    "inferencia_df['descuento_porcentaje'] = ((inferencia_df['precio_venta'] - inferencia_df['precio_base']) / inferencia_df['precio_base']) * 100\n",
    "\n",
    "# 4. Variables de competencia\n",
    "competidores = ['Amazon', 'Decathlon', 'Deporvillage']\n",
    "if all(col in inferencia_df.columns for col in competidores):\n",
    "    inferencia_df['precio_competencia'] = inferencia_df[competidores].mean(axis=1)\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "    inferencia_df = inferencia_df.drop(columns=competidores)\n",
    "else:\n",
    "    # Si no existen, usa el promedio histórico por producto (requiere df_historico cargado)\n",
    "    for producto_id in inferencia_df['producto_id'].unique():\n",
    "        precio_comp_hist = df_historico[df_historico['producto_id'] == producto_id]['precio_competencia'].mean()\n",
    "        inferencia_df.loc[inferencia_df['producto_id'] == producto_id, 'precio_competencia'] = precio_comp_hist\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "\n",
    "# 5. Codificación categórica (One Hot Encoding)\n",
    "for col in ['nombre', 'categoria', 'subcategoria']:\n",
    "    if col in inferencia_df.columns:\n",
    "        inferencia_df[f'{col}_h'] = inferencia_df[col]\n",
    "inferencia_df = pd.get_dummies(inferencia_df, columns=['nombre_h', 'categoria_h', 'subcategoria_h'], drop_first=False)\n",
    "\n",
    "# 6. Eliminar registros de octubre y dejar solo noviembre\n",
    "inferencia_df = inferencia_df[inferencia_df['mes'] == 11].copy()\n",
    "\n",
    "# 7. Guardar el DataFrame transformado\n",
    "ruta_final = './data/processed/inferencia_df_transformado.csv'\n",
    "inferencia_df.to_csv(ruta_final, index=False)\n",
    "print(f\"\\n✅ DataFrame transformado guardado en: {ruta_final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f025de58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>producto_id</th>\n",
       "      <th>nombre</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>precio_base</th>\n",
       "      <th>es_estrella</th>\n",
       "      <th>unidades_vendidas</th>\n",
       "      <th>precio_venta</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>...</th>\n",
       "      <th>subcategoria_h_Esterilla Yoga</th>\n",
       "      <th>subcategoria_h_Mancuernas Ajustables</th>\n",
       "      <th>subcategoria_h_Mochila Trekking</th>\n",
       "      <th>subcategoria_h_Pesa Rusa</th>\n",
       "      <th>subcategoria_h_Pesas Casa</th>\n",
       "      <th>subcategoria_h_Rodillera Yoga</th>\n",
       "      <th>subcategoria_h_Ropa Montaña</th>\n",
       "      <th>subcategoria_h_Ropa Running</th>\n",
       "      <th>subcategoria_h_Zapatillas Running</th>\n",
       "      <th>subcategoria_h_Zapatillas Trail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Nike Air Zoom Pegasus 40</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Nike Air Zoom Pegasus 40</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Nike Air Zoom Pegasus 40</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Nike Air Zoom Pegasus 40</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Nike Air Zoom Pegasus 40</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>PROD_024</td>\n",
       "      <td>Lotuscrafts Yoga Bolster</td>\n",
       "      <td>Wellness</td>\n",
       "      <td>Cojín Yoga</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>PROD_024</td>\n",
       "      <td>Lotuscrafts Yoga Bolster</td>\n",
       "      <td>Wellness</td>\n",
       "      <td>Cojín Yoga</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>PROD_024</td>\n",
       "      <td>Lotuscrafts Yoga Bolster</td>\n",
       "      <td>Wellness</td>\n",
       "      <td>Cojín Yoga</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2025-11-29</td>\n",
       "      <td>PROD_024</td>\n",
       "      <td>Lotuscrafts Yoga Bolster</td>\n",
       "      <td>Wellness</td>\n",
       "      <td>Cojín Yoga</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>PROD_024</td>\n",
       "      <td>Lotuscrafts Yoga Bolster</td>\n",
       "      <td>Wellness</td>\n",
       "      <td>Cojín Yoga</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fecha producto_id                    nombre categoria  \\\n",
       "168 2025-11-01    PROD_001  Nike Air Zoom Pegasus 40   Running   \n",
       "192 2025-11-02    PROD_001  Nike Air Zoom Pegasus 40   Running   \n",
       "216 2025-11-03    PROD_001  Nike Air Zoom Pegasus 40   Running   \n",
       "240 2025-11-04    PROD_001  Nike Air Zoom Pegasus 40   Running   \n",
       "264 2025-11-05    PROD_001  Nike Air Zoom Pegasus 40   Running   \n",
       "..         ...         ...                       ...       ...   \n",
       "791 2025-11-26    PROD_024  Lotuscrafts Yoga Bolster  Wellness   \n",
       "815 2025-11-27    PROD_024  Lotuscrafts Yoga Bolster  Wellness   \n",
       "839 2025-11-28    PROD_024  Lotuscrafts Yoga Bolster  Wellness   \n",
       "863 2025-11-29    PROD_024  Lotuscrafts Yoga Bolster  Wellness   \n",
       "887 2025-11-30    PROD_024  Lotuscrafts Yoga Bolster  Wellness   \n",
       "\n",
       "           subcategoria  precio_base  es_estrella  unidades_vendidas  \\\n",
       "168  Zapatillas Running          115         True                NaN   \n",
       "192  Zapatillas Running          115         True                NaN   \n",
       "216  Zapatillas Running          115         True                NaN   \n",
       "240  Zapatillas Running          115         True                NaN   \n",
       "264  Zapatillas Running          115         True                NaN   \n",
       "..                  ...          ...          ...                ...   \n",
       "791          Cojín Yoga           50        False                NaN   \n",
       "815          Cojín Yoga           50        False                NaN   \n",
       "839          Cojín Yoga           50        False                NaN   \n",
       "863          Cojín Yoga           50        False                NaN   \n",
       "887          Cojín Yoga           50        False                NaN   \n",
       "\n",
       "     precio_venta  ingresos  ...  subcategoria_h_Esterilla Yoga  \\\n",
       "168        115.00       NaN  ...                          False   \n",
       "192        115.00       NaN  ...                          False   \n",
       "216        115.00       NaN  ...                          False   \n",
       "240        115.00       NaN  ...                          False   \n",
       "264        115.00       NaN  ...                          False   \n",
       "..            ...       ...  ...                            ...   \n",
       "791         50.85       NaN  ...                          False   \n",
       "815         49.82       NaN  ...                          False   \n",
       "839         42.50       NaN  ...                          False   \n",
       "863         50.37       NaN  ...                          False   \n",
       "887         49.62       NaN  ...                          False   \n",
       "\n",
       "     subcategoria_h_Mancuernas Ajustables  subcategoria_h_Mochila Trekking  \\\n",
       "168                                 False                            False   \n",
       "192                                 False                            False   \n",
       "216                                 False                            False   \n",
       "240                                 False                            False   \n",
       "264                                 False                            False   \n",
       "..                                    ...                              ...   \n",
       "791                                 False                            False   \n",
       "815                                 False                            False   \n",
       "839                                 False                            False   \n",
       "863                                 False                            False   \n",
       "887                                 False                            False   \n",
       "\n",
       "    subcategoria_h_Pesa Rusa  subcategoria_h_Pesas Casa  \\\n",
       "168                    False                      False   \n",
       "192                    False                      False   \n",
       "216                    False                      False   \n",
       "240                    False                      False   \n",
       "264                    False                      False   \n",
       "..                       ...                        ...   \n",
       "791                    False                      False   \n",
       "815                    False                      False   \n",
       "839                    False                      False   \n",
       "863                    False                      False   \n",
       "887                    False                      False   \n",
       "\n",
       "     subcategoria_h_Rodillera Yoga  subcategoria_h_Ropa Montaña  \\\n",
       "168                          False                        False   \n",
       "192                          False                        False   \n",
       "216                          False                        False   \n",
       "240                          False                        False   \n",
       "264                          False                        False   \n",
       "..                             ...                          ...   \n",
       "791                          False                        False   \n",
       "815                          False                        False   \n",
       "839                          False                        False   \n",
       "863                          False                        False   \n",
       "887                          False                        False   \n",
       "\n",
       "     subcategoria_h_Ropa Running  subcategoria_h_Zapatillas Running  \\\n",
       "168                        False                               True   \n",
       "192                        False                               True   \n",
       "216                        False                               True   \n",
       "240                        False                               True   \n",
       "264                        False                               True   \n",
       "..                           ...                                ...   \n",
       "791                        False                              False   \n",
       "815                        False                              False   \n",
       "839                        False                              False   \n",
       "863                        False                              False   \n",
       "887                        False                              False   \n",
       "\n",
       "     subcategoria_h_Zapatillas Trail  \n",
       "168                            False  \n",
       "192                            False  \n",
       "216                            False  \n",
       "240                            False  \n",
       "264                            False  \n",
       "..                               ...  \n",
       "791                            False  \n",
       "815                            False  \n",
       "839                            False  \n",
       "863                            False  \n",
       "887                            False  \n",
       "\n",
       "[720 rows x 71 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferencia_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "607497d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 71)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferencia_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e8d18e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2025-11-01 00:00:00', '2025-11-02 00:00:00', '2025-11-03 00:00:00',\n",
       " '2025-11-04 00:00:00', '2025-11-05 00:00:00', '2025-11-06 00:00:00',\n",
       " '2025-11-07 00:00:00', '2025-11-08 00:00:00', '2025-11-09 00:00:00',\n",
       " '2025-11-10 00:00:00', '2025-11-11 00:00:00', '2025-11-12 00:00:00',\n",
       " '2025-11-13 00:00:00', '2025-11-14 00:00:00', '2025-11-15 00:00:00',\n",
       " '2025-11-16 00:00:00', '2025-11-17 00:00:00', '2025-11-18 00:00:00',\n",
       " '2025-11-19 00:00:00', '2025-11-20 00:00:00', '2025-11-21 00:00:00',\n",
       " '2025-11-22 00:00:00', '2025-11-23 00:00:00', '2025-11-24 00:00:00',\n",
       " '2025-11-25 00:00:00', '2025-11-26 00:00:00', '2025-11-27 00:00:00',\n",
       " '2025-11-28 00:00:00', '2025-11-29 00:00:00', '2025-11-30 00:00:00']\n",
       "Length: 30, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferencia_df.fecha.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a330e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías principales (igual que 1bENTRENMIENTO.IPYNB)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import streamlit as st\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f549eeb4",
   "metadata": {},
   "source": [
    "# Forecasting - Importación de librerías y carga de datos\n",
    "Este notebook importa las mismas librerías que el notebook de entrenamiento y carga el archivo de inferencia para análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf074d",
   "metadata": {},
   "source": [
    "## Forecasting de ventas 2025\n",
    "Este notebook importa las librerías necesarias y carga los datos de ventas para inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3defff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports principales para el forecasting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import streamlit as st\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f5fa9",
   "metadata": {},
   "source": [
    "## Cargar archivo de ventas para inferencia\n",
    "Se carga el archivo 'data/raw/inferencia/ventas_2025_inferencia.csv' en un DataFrame llamado inferencia_df y se muestran las primeras filas para verificar la carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c52e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Archivo cargado con éxito!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>producto_id</th>\n",
       "      <th>nombre</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>precio_base</th>\n",
       "      <th>es_estrella</th>\n",
       "      <th>unidades_vendidas</th>\n",
       "      <th>precio_venta</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>Decathlon</th>\n",
       "      <th>Deporvillage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Nike Air Zoom Pegasus 40</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>113.13</td>\n",
       "      <td>2941.38</td>\n",
       "      <td>89.51</td>\n",
       "      <td>113.43</td>\n",
       "      <td>104.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_002</td>\n",
       "      <td>Adidas Ultraboost 23</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>135</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>141.89</td>\n",
       "      <td>3831.03</td>\n",
       "      <td>128.73</td>\n",
       "      <td>112.91</td>\n",
       "      <td>122.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_003</td>\n",
       "      <td>Asics Gel Nimbus 25</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.79</td>\n",
       "      <td>428.95</td>\n",
       "      <td>84.28</td>\n",
       "      <td>74.51</td>\n",
       "      <td>85.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_004</td>\n",
       "      <td>New Balance Fresh Foam X 1080v12</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.19</td>\n",
       "      <td>228.57</td>\n",
       "      <td>75.54</td>\n",
       "      <td>70.32</td>\n",
       "      <td>71.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-25</td>\n",
       "      <td>PROD_005</td>\n",
       "      <td>Nike Dri-FIT Miler</td>\n",
       "      <td>Running</td>\n",
       "      <td>Ropa Running</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.48</td>\n",
       "      <td>106.44</td>\n",
       "      <td>33.84</td>\n",
       "      <td>31.32</td>\n",
       "      <td>34.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha producto_id                            nombre categoria  \\\n",
       "0  2025-10-25    PROD_001          Nike Air Zoom Pegasus 40   Running   \n",
       "1  2025-10-25    PROD_002              Adidas Ultraboost 23   Running   \n",
       "2  2025-10-25    PROD_003               Asics Gel Nimbus 25   Running   \n",
       "3  2025-10-25    PROD_004  New Balance Fresh Foam X 1080v12   Running   \n",
       "4  2025-10-25    PROD_005                Nike Dri-FIT Miler   Running   \n",
       "\n",
       "         subcategoria  precio_base  es_estrella  unidades_vendidas  \\\n",
       "0  Zapatillas Running          115         True               26.0   \n",
       "1  Zapatillas Running          135         True               27.0   \n",
       "2  Zapatillas Running           85        False                5.0   \n",
       "3  Zapatillas Running           75        False                3.0   \n",
       "4        Ropa Running           35        False                3.0   \n",
       "\n",
       "   precio_venta  ingresos  Amazon  Decathlon  Deporvillage  \n",
       "0        113.13   2941.38   89.51     113.43        104.78  \n",
       "1        141.89   3831.03  128.73     112.91        122.88  \n",
       "2         85.79    428.95   84.28      74.51         85.57  \n",
       "3         76.19    228.57   75.54      70.32         71.13  \n",
       "4         35.48    106.44   33.84      31.32         34.41  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Definimos la ruta exacta usando una \"r\" antes de las comillas para evitar errores de sintaxis en Windows\n",
    "inferencia_path = r\"C:\\Users\\Usuario\\Desktop\\Data Science Proyecto\\data\\raw\\inferencia\\ventas_2025_inferencia.csv\"\n",
    "\n",
    "# 2. Cargamos el archivo\n",
    "try:\n",
    "    inferencia_df = pd.read_csv(inferencia_path)\n",
    "    print(\"¡Archivo cargado con éxito!\")\n",
    "    \n",
    "    # 3. Mostramos las primeras filas\n",
    "    display(inferencia_df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: No se encontró el archivo. Revisa que el nombre 'ventas_2025_inferencia.csv' sea correcto.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5127de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Archivo guardado con éxito en ../data/processed/inferencia_df_transformado.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_9620\\2095990916.py:18: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  inferencia_df['es_festivo'] = inferencia_df['fecha'].isin(festivos_es).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>producto_id</th>\n",
       "      <th>nombre</th>\n",
       "      <th>categoria</th>\n",
       "      <th>subcategoria</th>\n",
       "      <th>precio_base</th>\n",
       "      <th>es_estrella</th>\n",
       "      <th>unidades_vendidas</th>\n",
       "      <th>precio_venta</th>\n",
       "      <th>ingresos</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_precio</th>\n",
       "      <th>unidades_vendidas_lag1</th>\n",
       "      <th>unidades_vendidas_lag2</th>\n",
       "      <th>unidades_vendidas_lag3</th>\n",
       "      <th>unidades_vendidas_lag4</th>\n",
       "      <th>unidades_vendidas_lag5</th>\n",
       "      <th>unidades_vendidas_lag6</th>\n",
       "      <th>unidades_vendidas_lag7</th>\n",
       "      <th>unidades_vendidas_ma7</th>\n",
       "      <th>descuento_porcentaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>PROD_001</td>\n",
       "      <td>Nike Air Zoom Pegasus 40</td>\n",
       "      <td>Running</td>\n",
       "      <td>Zapatillas Running</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.406212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fecha producto_id                    nombre categoria  \\\n",
       "168 2025-11-01    PROD_001  Nike Air Zoom Pegasus 40   Running   \n",
       "\n",
       "           subcategoria  precio_base  es_estrella  unidades_vendidas  \\\n",
       "168  Zapatillas Running          115         True                NaN   \n",
       "\n",
       "     precio_venta  ingresos  ...  ratio_precio  unidades_vendidas_lag1  \\\n",
       "168         115.0       NaN  ...      1.406212                     1.0   \n",
       "\n",
       "     unidades_vendidas_lag2 unidades_vendidas_lag3  unidades_vendidas_lag4  \\\n",
       "168                     6.0                    3.0                     6.0   \n",
       "\n",
       "     unidades_vendidas_lag5  unidades_vendidas_lag6  unidades_vendidas_lag7  \\\n",
       "168                     3.0                     2.0                     2.0   \n",
       "\n",
       "     unidades_vendidas_ma7  descuento_porcentaje  \n",
       "168               3.285714                   0.0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "import os\n",
    "\n",
    "# 1. Convertir fecha\n",
    "inferencia_df['fecha'] = pd.to_datetime(inferencia_df['fecha'])\n",
    "\n",
    "# 2. Variables temporales básicas\n",
    "inferencia_df['año'] = inferencia_df['fecha'].dt.year\n",
    "inferencia_df['mes'] = inferencia_df['fecha'].dt.month\n",
    "inferencia_df['dia_mes'] = inferencia_df['fecha'].dt.day\n",
    "inferencia_df['dia_semana'] = inferencia_df['fecha'].dt.day_name()\n",
    "inferencia_df['es_fin_semana'] = inferencia_df['dia_semana'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "\n",
    "# 3. Festivos\n",
    "festivos_es = holidays.country_holidays('ES', years=inferencia_df['fecha'].dt.year.unique())\n",
    "inferencia_df['es_festivo'] = inferencia_df['fecha'].isin(festivos_es).astype(int)\n",
    "\n",
    "# 13. (MOVIDO ARRIBA) Gestión de Precios de Competencia\n",
    "# Calculamos primero para tener las referencias de precio antes de los lags\n",
    "columnas_comp = ['Amazon', 'Decathlon', 'Deporvillage']\n",
    "if set(columnas_comp).issubset(inferencia_df.columns):\n",
    "    # El precio de la competencia es el mínimo encontrado en esas tiendas\n",
    "    inferencia_df['precio_competencia'] = inferencia_df[columnas_comp].min(axis=1)\n",
    "    # Ratio entre nuestro precio de venta y la competencia\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "    # IMPORTANTE: No hacemos .drop todavía si necesitas esos datos para las unidades\n",
    "\n",
    "# 10. Lags y media móvil (Basado en 'unidades_vendidas')\n",
    "# Si 'unidades_vendidas' no viene calculada, asegúrate de que exista la columna\n",
    "if 'unidades_vendidas' not in inferencia_df.columns:\n",
    "    print(\"Advertencia: 'unidades_vendidas' no encontrada. Se creará con ceros para el cálculo.\")\n",
    "    inferencia_df['unidades_vendidas'] = 0 \n",
    "\n",
    "lags = range(1, 8)\n",
    "for lag in lags:\n",
    "    inferencia_df[f'unidades_vendidas_lag{lag}'] = inferencia_df.groupby('año')['unidades_vendidas'].shift(lag)\n",
    "\n",
    "# Media móvil de 7 días\n",
    "for year in inferencia_df['año'].unique():\n",
    "    mask = inferencia_df['año'] == year\n",
    "    inferencia_df.loc[mask, 'unidades_vendidas_ma7'] = (\n",
    "        inferencia_df.loc[mask, 'unidades_vendidas'].shift(1).rolling(window=7).mean()\n",
    "    )\n",
    "\n",
    "# 11. Limpieza de Nulos (necesario tras crear lags)\n",
    "inferencia_df = inferencia_df.dropna(subset=[f'unidades_vendidas_lag{l}' for l in lags] + ['unidades_vendidas_ma7'])\n",
    "\n",
    "# 12. Variable de descuento (Usando 'precio_base' detectado en entrenamiento)\n",
    "# Cambié 'precio_original' por 'precio_base' para evitar el KeyError anterior\n",
    "inferencia_df['descuento_porcentaje'] = (\n",
    "    (inferencia_df['precio_base'] - inferencia_df['precio_venta']) / inferencia_df['precio_base']\n",
    ") * 100\n",
    "\n",
    "# 14. Filtrado final: Solo Noviembre y limpieza de columnas sobrantes\n",
    "inferencia_df = inferencia_df[inferencia_df['fecha'].dt.month == 11]\n",
    "\n",
    "# Ahora sí podemos limpiar las columnas de competencia originales si ya no las usas\n",
    "columnas_a_borrar = [c for c in columnas_comp if c in inferencia_df.columns]\n",
    "if columnas_a_borrar:\n",
    "    inferencia_df = inferencia_df.drop(columns=columnas_a_borrar)\n",
    "\n",
    "# Guardar\n",
    "output_path = \"../data/processed/inferencia_df_transformado.csv\"\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "inferencia_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"OK. Archivo guardado con éxito en {output_path}\")\n",
    "display(inferencia_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1414d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros después de crear lags:  1\n",
      "Registros con nulos en lags:\n",
      "unidades_vendidas_lag1    0\n",
      "unidades_vendidas_lag2    0\n",
      "unidades_vendidas_lag3    0\n",
      "unidades_vendidas_lag4    0\n",
      "unidades_vendidas_lag5    0\n",
      "unidades_vendidas_lag6    0\n",
      "unidades_vendidas_lag7    0\n",
      "unidades_vendidas_ma7     0\n",
      "dtype: int64\n",
      "\n",
      "N primeros registros con lags (Vista previa):\n",
      "     unidades_vendidas_lag1  unidades_vendidas_lag2  unidades_vendidas_lag3  \\\n",
      "168                    80.0                    66.0                    15.0   \n",
      "\n",
      "     unidades_vendidas_lag4  unidades_vendidas_lag5  unidades_vendidas_lag6  \\\n",
      "168                    13.0                    18.0                    12.0   \n",
      "\n",
      "     unidades_vendidas_lag7  unidades_vendidas_ma7      fecha  mes  \n",
      "168                    16.0              31.428571 2025-11-01   11  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Carga df procesado con la ruta y nombre de archivo correctos\n",
    "# Usamos ./data/processed/DF.csv basado en tu estructura de carpetas\n",
    "df_historico = pd.read_csv('./data/processed/DF.csv')\n",
    "df_historico['fecha'] = pd.to_datetime(df_historico['fecha'])\n",
    "\n",
    "# Aseguramos que inferencia_df tenga formato datetime y la columna 'mes'\n",
    "inferencia_df['fecha'] = pd.to_datetime(inferencia_df['fecha'])\n",
    "inferencia_df['mes'] = inferencia_df['fecha'].dt.month\n",
    "\n",
    "# Configuración de lags\n",
    "lags = range(1, 8)\n",
    "\n",
    "# Ordenar por producto y fecha para que los lags tengan sentido cronológico\n",
    "inferencia_df = inferencia_df.sort_values(['producto_id', 'fecha'])\n",
    "\n",
    "# Bucle para procesar cada producto\n",
    "for producto_id in inferencia_df['producto_id'].unique():\n",
    "    # Obtener últimos 7 registros del histórico para este producto\n",
    "    df_prod_hist = df_historico[df_historico['producto_id'] == producto_id].sort_values('fecha').tail(7)\n",
    "    valores_hist = df_prod_hist['unidades_vendidas'].values\n",
    "\n",
    "    # Obtener registros de inferencia para este producto\n",
    "    mask_prod = inferencia_df['producto_id'] == producto_id\n",
    "    indices_prod = inferencia_df[mask_prod].index\n",
    "\n",
    "    # Inicializar lags y media móvil\n",
    "    for i, idx in enumerate(indices_prod):\n",
    "        # Lags: Si no hay suficiente historia en inferencia, busca en valores_hist\n",
    "        for lag in lags:\n",
    "            col_name = f'unidades_vendidas_lag{lag}'\n",
    "            if i >= lag:\n",
    "                inferencia_df.loc[idx, col_name] = inferencia_df.loc[indices_prod[i-lag], 'unidades_vendidas']\n",
    "            else:\n",
    "                hist_idx = len(valores_hist) - lag + i\n",
    "                if hist_idx >= 0:\n",
    "                    inferencia_df.loc[idx, col_name] = valores_hist[hist_idx]\n",
    "                else:\n",
    "                    inferencia_df.loc[idx, col_name] = np.nan\n",
    "\n",
    "        # Media móvil de 7 días (MA7)\n",
    "        valores_ma = []\n",
    "        for j in range(1, 8): # Miramos los 7 días anteriores\n",
    "            if i - j >= 0:\n",
    "                valores_ma.append(inferencia_df.loc[indices_prod[i-j], 'unidades_vendidas'])\n",
    "            else:\n",
    "                hist_idx = len(valores_hist) + (i - j)\n",
    "                if hist_idx >= 0:\n",
    "                    valores_ma.append(valores_hist[hist_idx])\n",
    "        \n",
    "        if len(valores_ma) > 0:\n",
    "            inferencia_df.loc[idx, 'unidades_vendidas_ma7'] = np.mean(valores_ma)\n",
    "        else:\n",
    "            inferencia_df.loc[idx, 'unidades_vendidas_ma7'] = np.nan\n",
    "\n",
    "# --- IMPRESIONES DE CONTROL ---\n",
    "\n",
    "print(\"Registros después de crear lags: \", len(inferencia_df))\n",
    "\n",
    "# Columnas de lags para el reporte\n",
    "cols_lags = [f'unidades_vendidas_lag{lag}' for lag in lags]\n",
    "cols_reporte = cols_lags + ['unidades_vendidas_ma7']\n",
    "\n",
    "print(\"Registros con nulos en lags:\")\n",
    "print(inferencia_df[cols_reporte].isnull().sum())\n",
    "\n",
    "print(\"\\nN primeros registros con lags (Vista previa):\")\n",
    "# 'mes' y 'fecha' ahora están garantizados\n",
    "print(inferencia_df[cols_reporte + ['fecha', 'mes']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a51bdeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de fecha en inferencia_df: datetime64[ns]\n",
      "Columnas actuales: ['fecha', 'producto_id', 'nombre', 'categoria', 'subcategoria', 'precio_base', 'es_estrella', 'unidades_vendidas', 'precio_venta', 'ingresos', 'año', 'mes', 'dia_mes', 'dia_semana', 'es_fin_semana', 'es_festivo', 'precio_competencia', 'ratio_precio', 'unidades_vendidas_lag1', 'unidades_vendidas_lag2', 'unidades_vendidas_lag3', 'unidades_vendidas_lag4', 'unidades_vendidas_lag5', 'unidades_vendidas_lag6', 'unidades_vendidas_lag7', 'unidades_vendidas_ma7', 'descuento_porcentaje']\n"
     ]
    }
   ],
   "source": [
    "# 1. Convertir la columna 'fecha' a tipo datetime (como en tu imagen)\n",
    "inferencia_df['fecha'] = pd.to_datetime(inferencia_df['fecha'])\n",
    "\n",
    "# 2. Verificar la conversión (opcional, según tu imagen)\n",
    "print(\"Tipo de fecha en inferencia_df:\", inferencia_df['fecha'].dtype)\n",
    "\n",
    "# 3. ADAPTACIÓN: Crear la columna 'mes' necesaria para el resto de tu código\n",
    "# Esto evita el error KeyError: \"['mes'] not in index\"\n",
    "inferencia_df['mes'] = inferencia_df['fecha'].dt.month\n",
    "\n",
    "# 4. Verificar que 'mes' se creó correctamente\n",
    "print(\"Columnas actuales:\", inferencia_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1fd474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de fecha en inferencia_df: datetime64[ns]\n",
      "\n",
      "Verificación de nuevas columnas (mes y descuento):\n",
      "         fecha  mes producto_id  precio_base  precio_venta  \\\n",
      "168 2025-11-01   11    PROD_001          115         115.0   \n",
      "\n",
      "     descuento_porcentaje  \n",
      "168                   0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- ADAPTACIÓN IMAGEN 1: Conversión de fecha y creación de 'mes' ---\n",
    "# Convertir la columna 'fecha' a tipo datetime\n",
    "inferencia_df['fecha'] = pd.to_datetime(inferencia_df['fecha'])\n",
    "\n",
    "# IMPORTANTE: Creamos la columna 'mes' para evitar el KeyError detectado anteriormente\n",
    "inferencia_df['mes'] = inferencia_df['fecha'].dt.month\n",
    "\n",
    "# Verificar la conversión\n",
    "print(\"Tipo de fecha en inferencia_df:\", inferencia_df['fecha'].dtype)\n",
    "\n",
    "\n",
    "# --- ADAPTACIÓN IMAGEN 2: Variable de descuento ---\n",
    "# Fórmula: ((precio_venta - precio_base) / precio_base) * 100\n",
    "inferencia_df['descuento_porcentaje'] = ((inferencia_df['precio_venta'] - inferencia_df['precio_base']) / inferencia_df['precio_base']) * 100\n",
    "\n",
    "# Mostrar las primeras filas para verificar (incluyendo 'mes' para confirmar que existe)\n",
    "print(\"\\nVerificación de nuevas columnas (mes y descuento):\")\n",
    "columnas_verificacion = ['fecha', 'mes', 'producto_id', 'precio_base', 'precio_venta', 'descuento_porcentaje']\n",
    "print(inferencia_df[columnas_verificacion].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2e239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de fecha en inferencia_df: datetime64[ns]\n",
      "\n",
      "Primeras filas del DataFrame procesado:\n",
      "        fecha  mes producto_id  precio_venta  precio_competencia  \\\n",
      "0  2025-10-25   10    PROD_001        113.13          100.974426   \n",
      "24 2025-10-26   10    PROD_001        105.75          100.974426   \n",
      "48 2025-10-27   10    PROD_001        114.95          100.974426   \n",
      "72 2025-10-28   10    PROD_001        117.31          100.974426   \n",
      "96 2025-10-29   10    PROD_001        108.10          100.974426   \n",
      "\n",
      "    ratio_precio  descuento_porcentaje  \n",
      "0       1.120383             -1.626087  \n",
      "24      1.047295             -8.043478  \n",
      "48      1.138407             -0.043478  \n",
      "72      1.161779              2.008696  \n",
      "96      1.070568             -6.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. PROCESAMIENTO DE FECHAS (Basado en imagen 1) ---\n",
    "# Convertir la columna 'fecha' a tipo datetime\n",
    "inferencia_df['fecha'] = pd.to_datetime(inferencia_df['fecha'])\n",
    "\n",
    "# ADAPTACIÓN NECESARIA: Creamos la columna 'mes' para evitar KeyErrors futuros\n",
    "inferencia_df['mes'] = inferencia_df['fecha'].dt.month\n",
    "\n",
    "print(\"Tipo de fecha en inferencia_df:\", inferencia_df['fecha'].dtype)\n",
    "\n",
    "\n",
    "# --- 2. CÁLCULO DE DESCUENTO (Basado en imagen 2) ---\n",
    "# Fórmula: ((precio_venta - precio_base) / precio_base) * 100\n",
    "inferencia_df['descuento_porcentaje'] = ((inferencia_df['precio_venta'] - inferencia_df['precio_base']) / inferencia_df['precio_base']) * 100\n",
    "\n",
    "\n",
    "# --- 3. ANÁLISIS DE COMPETENCIA (Basado en imagen 3) ---\n",
    "# Verificamos si existen las columnas de competidores específicos\n",
    "competidores = ['Amazon', 'Decathlon', 'Deporvillage']\n",
    "\n",
    "if all(col in inferencia_df.columns for col in competidores):\n",
    "    # Caso A: Si las columnas existen, calculamos el promedio directo\n",
    "    inferencia_df['precio_competencia'] = inferencia_df[competidores].mean(axis=1)\n",
    "    # Variable ratio_precio: nuestro precio vs competencia\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "    # Limpiamos las columnas originales de competidores\n",
    "    inferencia_df = inferencia_df.drop(columns=competidores)\n",
    "else:\n",
    "    # Caso B: Si no existen, usamos el promedio histórico de df_historico por producto\n",
    "    for producto_id in inferencia_df['producto_id'].unique():\n",
    "        precio_comp_hist = df_historico[df_historico['producto_id'] == producto_id]['precio_competencia'].mean()\n",
    "        inferencia_df.loc[inferencia_df['producto_id'] == producto_id, 'precio_competencia'] = precio_comp_hist\n",
    "    \n",
    "    # Calculamos el ratio con los valores históricos obtenidos\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "\n",
    "\n",
    "# --- VERIFICACIÓN FINAL ---\n",
    "print(\"\\nPrimeras filas del DataFrame procesado:\")\n",
    "columnas_vista = ['fecha', 'mes', 'producto_id', 'precio_venta', 'precio_competencia', 'ratio_precio', 'descuento_porcentaje']\n",
    "print(inferencia_df[columnas_vista].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de fecha en inferencia_df: datetime64[ns]\n",
      "\n",
      "Verificación de descuento:\n",
      "        fecha producto_id  precio_base  precio_venta  descuento_porcentaje\n",
      "0  2025-10-25    PROD_001          115        113.13             -1.626087\n",
      "24 2025-10-26    PROD_001          115        105.75             -8.043478\n",
      "48 2025-10-27    PROD_001          115        114.95             -0.043478\n",
      "72 2025-10-28    PROD_001          115        117.31              2.008696\n",
      "96 2025-10-29    PROD_001          115        108.10             -6.000000\n",
      "\n",
      "--- Estadísticas antes del filtrado ---\n",
      "Registros totales antes del filtrado: 888\n",
      "Registros de octubre: 168\n",
      "Registros de noviembre: 720\n",
      "\n",
      "Registros después de filtrar solo noviembre: 720\n",
      "Rango de fechas: 2025-11-01 00:00:00 a 2025-11-30 00:00:00\n",
      "Productos únicos: 24\n",
      "\n",
      "⚠️ Atención: Hay 5064 valores nulos en variables de lag en noviembre:\n",
      "unidades_vendidas_lag1    696\n",
      "unidades_vendidas_lag2    672\n",
      "unidades_vendidas_lag3    648\n",
      "unidades_vendidas_lag4    624\n",
      "unidades_vendidas_lag5    600\n",
      "unidades_vendidas_lag6    576\n",
      "unidades_vendidas_lag7    552\n",
      "unidades_vendidas_ma7     696\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. PROCESAMIENTO DE FECHAS (Imagen 1) ---\n",
    "# Convertir la columna 'fecha' a tipo datetime\n",
    "inferencia_df['fecha'] = pd.to_datetime(inferencia_df['fecha'])\n",
    "# Extraemos el 'mes' para evitar errores de referencia y facilitar el filtrado final\n",
    "inferencia_df['mes'] = inferencia_df['fecha'].dt.month\n",
    "print(f\"Tipo de fecha en inferencia_df: {inferencia_df['fecha'].dtype}\")\n",
    "\n",
    "# --- 2. VARIABLE DE DESCUENTO (Imagen 2) ---\n",
    "# Fórmula: ((precio_venta - precio_base) / precio_base) * 100\n",
    "inferencia_df['descuento_porcentaje'] = ((inferencia_df['precio_venta'] - inferencia_df['precio_base']) / inferencia_df['precio_base']) * 100\n",
    "print(\"\\nVerificación de descuento:\")\n",
    "print(inferencia_df[['fecha', 'producto_id', 'precio_base', 'precio_venta', 'descuento_porcentaje']].head())\n",
    "\n",
    "# --- 3. ANÁLISIS DE COMPETENCIA (Imágenes 3 y 4) ---\n",
    "competidores = ['Amazon', 'Decathlon', 'Deporvillage']\n",
    "\n",
    "# Si las columnas existen, calculamos el promedio directamente\n",
    "if all(col in inferencia_df.columns for col in competidores):\n",
    "    inferencia_df['precio_competencia'] = inferencia_df[competidores].mean(axis=1)\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "    # Limpiamos las columnas originales para dejar solo el promedio\n",
    "    inferencia_df = inferencia_df.drop(columns=competidores)\n",
    "else:\n",
    "    # Si no existen, usamos el promedio histórico por producto de df_historico\n",
    "    for producto_id in inferencia_df['producto_id'].unique():\n",
    "        precio_comp_hist = df_historico[df_historico['producto_id'] == producto_id]['precio_competencia'].mean()\n",
    "        inferencia_df.loc[inferencia_df['producto_id'] == producto_id, 'precio_competencia'] = precio_comp_hist\n",
    "    \n",
    "    # Calculamos el ratio con los valores históricos obtenidos\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "\n",
    "# --- 4. FILTRADO Y GUARDADO FINAL (Imágenes 5 y 6) ---\n",
    "print(\"\\n--- Estadísticas antes del filtrado ---\")\n",
    "print(f\"Registros totales antes del filtrado: {len(inferencia_df)}\")\n",
    "print(f\"Registros de octubre: {len(inferencia_df[inferencia_df['mes'] == 10])}\")\n",
    "print(f\"Registros de noviembre: {len(inferencia_df[inferencia_df['mes'] == 11])}\")\n",
    "\n",
    "# Eliminar todos los registros de octubre y mantener solo noviembre\n",
    "inferencia_df = inferencia_df[inferencia_df['mes'] == 11].copy()\n",
    "\n",
    "print(f\"\\nRegistros después de filtrar solo noviembre: {len(inferencia_df)}\")\n",
    "print(f\"Rango de fechas: {inferencia_df['fecha'].min()} a {inferencia_df['fecha'].max()}\")\n",
    "print(f\"Productos únicos: {inferencia_df['producto_id'].nunique()}\")\n",
    "\n",
    "# Verificar si hay nulos en las variables de lags para noviembre\n",
    "cols_lag_ma = [f'unidades_vendidas_lag{lag}' for lag in range(1, 8)] + ['unidades_vendidas_ma7']\n",
    "nulos_noviembre = inferencia_df[cols_lag_ma].isnull().sum()\n",
    "\n",
    "if nulos_noviembre.sum() > 0:\n",
    "    print(f\"\\n⚠️ Atención: Hay {nulos_noviembre.sum()} valores nulos en variables de lag en noviembre:\")\n",
    "    print(nulos_noviembre[nulos_noviembre > 0])\n",
    "else:\n",
    "    print(\"\\n✅ No hay valores nulos en las variables de lag para noviembre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa1f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de fecha en inferencia_df: datetime64[ns]\n",
      "\n",
      "Verificación de descuento:\n",
      "         fecha producto_id  precio_base  precio_venta  descuento_porcentaje\n",
      "168 2025-11-01    PROD_001          115         115.0                   0.0\n",
      "192 2025-11-02    PROD_001          115         115.0                   0.0\n",
      "216 2025-11-03    PROD_001          115         115.0                   0.0\n",
      "240 2025-11-04    PROD_001          115         115.0                   0.0\n",
      "264 2025-11-05    PROD_001          115         115.0                   0.0\n",
      "\n",
      "--- Estadísticas antes del filtrado ---\n",
      "Registros totales antes del filtrado: 720\n",
      "Registros de octubre: 0\n",
      "Registros de noviembre: 720\n",
      "\n",
      "Registros después de filtrar solo noviembre: 720\n",
      "Rango de fechas: 2025-11-01 00:00:00 a 2025-11-30 00:00:00\n",
      "Productos únicos: 24\n",
      "\n",
      "⚠️ Atención: Hay 5064 valores nulos en variables de lag en noviembre:\n",
      "unidades_vendidas_lag1    696\n",
      "unidades_vendidas_lag2    672\n",
      "unidades_vendidas_lag3    648\n",
      "unidades_vendidas_lag4    624\n",
      "unidades_vendidas_lag5    600\n",
      "unidades_vendidas_lag6    576\n",
      "unidades_vendidas_lag7    552\n",
      "unidades_vendidas_ma7     696\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. PROCESAMIENTO DE FECHAS (Imagen 1) ---\n",
    "# Convertir la columna 'fecha' a tipo datetime\n",
    "inferencia_df['fecha'] = pd.to_datetime(inferencia_df['fecha'])\n",
    "# Extraemos el 'mes' para evitar errores de referencia y facilitar el filtrado final\n",
    "inferencia_df['mes'] = inferencia_df['fecha'].dt.month\n",
    "print(f\"Tipo de fecha en inferencia_df: {inferencia_df['fecha'].dtype}\")\n",
    "\n",
    "# --- 2. VARIABLE DE DESCUENTO (Imagen 2) ---\n",
    "# Fórmula: ((precio_venta - precio_base) / precio_base) * 100\n",
    "inferencia_df['descuento_porcentaje'] = ((inferencia_df['precio_venta'] - inferencia_df['precio_base']) / inferencia_df['precio_base']) * 100\n",
    "print(\"\\nVerificación de descuento:\")\n",
    "print(inferencia_df[['fecha', 'producto_id', 'precio_base', 'precio_venta', 'descuento_porcentaje']].head())\n",
    "\n",
    "# --- 3. ANÁLISIS DE COMPETENCIA (Imágenes 3 y 4) ---\n",
    "competidores = ['Amazon', 'Decathlon', 'Deporvillage']\n",
    "\n",
    "# Si las columnas existen, calculamos el promedio directamente\n",
    "if all(col in inferencia_df.columns for col in competidores):\n",
    "    inferencia_df['precio_competencia'] = inferencia_df[competidores].mean(axis=1)\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "    # Limpiamos las columnas originales para dejar solo el promedio\n",
    "    inferencia_df = inferencia_df.drop(columns=competidores)\n",
    "else:\n",
    "    # Si no existen, usamos el promedio histórico por producto de df_historico\n",
    "    for producto_id in inferencia_df['producto_id'].unique():\n",
    "        precio_comp_hist = df_historico[df_historico['producto_id'] == producto_id]['precio_competencia'].mean()\n",
    "        inferencia_df.loc[inferencia_df['producto_id'] == producto_id, 'precio_competencia'] = precio_comp_hist\n",
    "    \n",
    "    # Calculamos el ratio con los valores históricos obtenidos\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "\n",
    "# --- 4. FILTRADO Y GUARDADO FINAL (Imágenes 5 y 6) ---\n",
    "print(\"\\n--- Estadísticas antes del filtrado ---\")\n",
    "print(f\"Registros totales antes del filtrado: {len(inferencia_df)}\")\n",
    "print(f\"Registros de octubre: {len(inferencia_df[inferencia_df['mes'] == 10])}\")\n",
    "print(f\"Registros de noviembre: {len(inferencia_df[inferencia_df['mes'] == 11])}\")\n",
    "\n",
    "# Eliminar todos los registros de octubre y mantener solo noviembre\n",
    "inferencia_df = inferencia_df[inferencia_df['mes'] == 11].copy()\n",
    "\n",
    "print(f\"\\nRegistros después de filtrar solo noviembre: {len(inferencia_df)}\")\n",
    "print(f\"Rango de fechas: {inferencia_df['fecha'].min()} a {inferencia_df['fecha'].max()}\")\n",
    "print(f\"Productos únicos: {inferencia_df['producto_id'].nunique()}\")\n",
    "\n",
    "# Verificar si hay nulos en las variables de lags para noviembre\n",
    "cols_lag_ma = [f'unidades_vendidas_lag{lag}' for lag in range(1, 8)] + ['unidades_vendidas_ma7']\n",
    "nulos_noviembre = inferencia_df[cols_lag_ma].isnull().sum()\n",
    "\n",
    "if nulos_noviembre.sum() > 0:\n",
    "    print(f\"\\n⚠️ Atención: Hay {nulos_noviembre.sum()} valores nulos en variables de lag en noviembre:\")\n",
    "    print(nulos_noviembre[nulos_noviembre > 0])\n",
    "else:\n",
    "    print(\"\\n✅ No hay valores nulos en las variables de lag para noviembre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21efd6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de fecha en inferencia_df: datetime64[ns]\n",
      "\n",
      "Verificación de cálculo de descuento:\n",
      "         fecha producto_id  precio_base  precio_venta  descuento_porcentaje\n",
      "168 2025-11-01    PROD_001          115         115.0                   0.0\n",
      "192 2025-11-02    PROD_001          115         115.0                   0.0\n",
      "216 2025-11-03    PROD_001          115         115.0                   0.0\n",
      "240 2025-11-04    PROD_001          115         115.0                   0.0\n",
      "264 2025-11-05    PROD_001          115         115.0                   0.0\n",
      "\n",
      "--- Estadísticas antes del filtrado ---\n",
      "Registros totales antes del filtrado: 720\n",
      "Registros de octubre (mes 10): 0\n",
      "Registros de noviembre (mes 11): 720\n",
      "\n",
      "Registros después de filtrar solo noviembre: 720\n",
      "Fechas en inferencia_df: 2025-11-01 00:00:00 a 2025-11-30 00:00:00\n",
      "Productos únicos: 24\n",
      "\n",
      "⚠️ Atención: Hay 5064 valores nulos en variables de lag en noviembre:\n",
      "unidades_vendidas_lag1    696\n",
      "unidades_vendidas_lag2    672\n",
      "unidades_vendidas_lag3    648\n",
      "unidades_vendidas_lag4    624\n",
      "unidades_vendidas_lag5    600\n",
      "unidades_vendidas_lag6    576\n",
      "unidades_vendidas_lag7    552\n",
      "unidades_vendidas_ma7     696\n",
      "dtype: int64\n",
      "\n",
      "DataFrame transformado guardado en: ./data/processed/inferencia_df_transformado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. PROCESAMIENTO DE FECHAS Y COLUMNA 'MES' (Imagen 1) ---\n",
    "# Convertir la columna 'fecha' a tipo datetime\n",
    "inferencia_df['fecha'] = pd.to_datetime(inferencia_df['fecha'])\n",
    "# ADAPTACIÓN: Crear la columna 'mes' necesaria para el filtrado y evitar KeyErrors\n",
    "inferencia_df['mes'] = inferencia_df['fecha'].dt.month\n",
    "print(f\"Tipo de fecha en inferencia_df: {inferencia_df['fecha'].dtype}\")\n",
    "\n",
    "# --- 2. VARIABLE DE DESCUENTO PORCENTAJE (Imagen 2) ---\n",
    "# Fórmula: ((precio_venta - precio_base) / precio_base) * 100\n",
    "inferencia_df['descuento_porcentaje'] = ((inferencia_df['precio_venta'] - inferencia_df['precio_base']) / inferencia_df['precio_base']) * 100\n",
    "print(\"\\nVerificación de cálculo de descuento:\")\n",
    "print(inferencia_df[['fecha', 'producto_id', 'precio_base', 'precio_venta', 'descuento_porcentaje']].head())\n",
    "\n",
    "# --- 3. ANÁLISIS DE COMPETENCIA (Imágenes 3 y 4) ---\n",
    "competidores = ['Amazon', 'Decathlon', 'Deporvillage']\n",
    "\n",
    "# Verificamos si las columnas de competencia existen en el DataFrame actual\n",
    "if all(col in inferencia_df.columns for col in competidores):\n",
    "    # Caso A: Calculamos el promedio de la competencia y el ratio nuestro precio vs competencia\n",
    "    inferencia_df['precio_competencia'] = inferencia_df[competidores].mean(axis=1)\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "    # Limpiamos las columnas originales de competidores\n",
    "    inferencia_df = inferencia_df.drop(columns=competidores)\n",
    "else:\n",
    "    # Caso B: Usar el promedio histórico por producto si no hay datos actuales\n",
    "    for producto_id in inferencia_df['producto_id'].unique():\n",
    "        precio_comp_hist = df_historico[df_historico['producto_id'] == producto_id]['precio_competencia'].mean()\n",
    "        inferencia_df.loc[inferencia_df['producto_id'] == producto_id, 'precio_competencia'] = precio_comp_hist\n",
    "    \n",
    "    # Calculamos el ratio con los valores históricos obtenidos\n",
    "    inferencia_df['ratio_precio'] = inferencia_df['precio_venta'] / inferencia_df['precio_competencia']\n",
    "\n",
    "# --- 4. FILTRADO Y GUARDADO FINAL (Imágenes 5, 6 y 7) ---\n",
    "print(\"\\n--- Estadísticas antes del filtrado ---\")\n",
    "print(f\"Registros totales antes del filtrado: {len(inferencia_df)}\")\n",
    "print(f\"Registros de octubre (mes 10): {len(inferencia_df[inferencia_df['mes'] == 10])}\")\n",
    "print(f\"Registros de noviembre (mes 11): {len(inferencia_df[inferencia_df['mes'] == 11])}\")\n",
    "\n",
    "# Eliminar todos los registros de octubre (usados para calcular lags) y mantener solo noviembre\n",
    "inferencia_df = inferencia_df[inferencia_df['mes'] == 11].copy()\n",
    "\n",
    "print(f\"\\nRegistros después de filtrar solo noviembre: {len(inferencia_df)}\")\n",
    "print(f\"Fechas en inferencia_df: {inferencia_df['fecha'].min()} a {inferencia_df['fecha'].max()}\")\n",
    "print(f\"Productos únicos: {inferencia_df['producto_id'].nunique()}\")\n",
    "\n",
    "# Verificar si hay nulos en las variables de lags para el set final de noviembre\n",
    "cols_lag_ma = [f'unidades_vendidas_lag{lag}' for lag in range(1, 8)] + ['unidades_vendidas_ma7']\n",
    "nulos_noviembre = inferencia_df[cols_lag_ma].isnull().sum()\n",
    "\n",
    "if nulos_noviembre.sum() > 0:\n",
    "    print(f\"\\n⚠️ Atención: Hay {nulos_noviembre.sum()} valores nulos en variables de lag en noviembre:\")\n",
    "    print(nulos_noviembre[nulos_noviembre > 0])\n",
    "else:\n",
    "    print(\"\\n✅ No hay valores nulos en las variables de lag para noviembre\")\n",
    "\n",
    "# --- 5. GUARDAR RESULTADOS (Imagen 7) ---\n",
    "ruta_guardado = './data/processed/inferencia_df_transformado.csv'\n",
    "inferencia_df.to_csv(ruta_guardado, index=False)\n",
    "print(f\"\\nDataFrame transformado guardado en: {ruta_guardado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed6b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrando solo noviembre y guardando el DataFrame transformado...\n",
      "Registros totales antes del filtrado: 720\n",
      "Registros de octubre: 0\n",
      "Registros de noviembre: 720\n",
      "\n",
      "⚠️ Atención: Hay 5064 valores nulos en variables de lag en noviembre:\n",
      "unidades_vendidas_lag1    696\n",
      "unidades_vendidas_lag2    672\n",
      "unidades_vendidas_lag3    648\n",
      "unidades_vendidas_lag4    624\n",
      "unidades_vendidas_lag5    600\n",
      "unidades_vendidas_lag6    576\n",
      "unidades_vendidas_lag7    552\n",
      "unidades_vendidas_ma7     696\n",
      "dtype: int64\n",
      "\n",
      "==============================\n",
      "RESUMEN FINAL:\n",
      "Total de registros guardados: 720\n",
      "Total de columnas: 22\n",
      "Productos únicos: 24\n",
      "Rango de fechas: 2025-11-01 00:00:00 a 2025-11-30 00:00:00\n",
      "Archivo guardado exitosamente en: ./data/processed/inferencia_df_transformado.csv\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- FILTRADO FINAL (Basado en tus imágenes de control) ---\n",
    "print(\"Filtrando solo noviembre y guardando el DataFrame transformado...\")\n",
    "\n",
    "# 1. Estadísticas previas al filtrado para control\n",
    "print(f\"Registros totales antes del filtrado: {len(inferencia_df)}\")\n",
    "print(f\"Registros de octubre: {len(inferencia_df[inferencia_df['mes'] == 10])}\")\n",
    "print(f\"Registros de noviembre: {len(inferencia_df[inferencia_df['mes'] == 11])}\")\n",
    "\n",
    "# 2. Eliminar registros de octubre (usados solo para cálculos) y mantener noviembre\n",
    "inferencia_df = inferencia_df[inferencia_df['mes'] == 11].copy()\n",
    "\n",
    "# 3. Verificación de nulos en variables técnicas de noviembre\n",
    "cols_lag_ma = [f'unidades_vendidas_lag{lag}' for lag in range(1, 8)] + ['unidades_vendidas_ma7']\n",
    "nulos_noviembre = inferencia_df[cols_lag_ma].isnull().sum()\n",
    "\n",
    "if nulos_noviembre.sum() > 0:\n",
    "    print(f\"\\n⚠️ Atención: Hay {nulos_noviembre.sum()} valores nulos en variables de lag en noviembre:\")\n",
    "    print(nulos_noviembre[nulos_noviembre > 0])\n",
    "else:\n",
    "    print(\"\\n✅ No hay valores nulos en las variables de lag para noviembre\")\n",
    "\n",
    "# --- GUARDADO ADAPTADO A TU ESTRUCTURA ---\n",
    "# Usamos la ruta relativa correcta desde la carpeta 'notebooks'\n",
    "ruta_final = './data/processed/inferencia_df_transformado.csv'\n",
    "\n",
    "inferencia_df.to_csv(ruta_final, index=False)\n",
    "\n",
    "# --- RESUMEN FINAL PARA CONSOLA ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"RESUMEN FINAL:\")\n",
    "print(f\"Total de registros guardados: {len(inferencia_df)}\")\n",
    "print(f\"Total de columnas: {len(inferencia_df.columns)}\")\n",
    "print(f\"Productos únicos: {inferencia_df['producto_id'].nunique()}\")\n",
    "print(f\"Rango de fechas: {inferencia_df['fecha'].min()} a {inferencia_df['fecha'].max()}\")\n",
    "print(f\"Archivo guardado exitosamente en: {ruta_final}\")\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bf38e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 71)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferencia_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "99999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70c56d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha', 'producto_id', 'nombre', 'categoria', 'subcategoria',\n",
       "       'precio_base', 'es_estrella', 'unidades_vendidas', 'precio_venta',\n",
       "       'ingresos', 'año', 'mes', 'dia_mes', 'dia_semana', 'es_fin_semana',\n",
       "       'es_festivo', 'unidades_vendidas_lag1', 'unidades_vendidas_lag2',\n",
       "       'unidades_vendidas_lag3', 'unidades_vendidas_lag4',\n",
       "       'unidades_vendidas_lag5', 'unidades_vendidas_lag6',\n",
       "       'unidades_vendidas_lag7', 'unidades_vendidas_ma7',\n",
       "       'descuento_porcentaje', 'precio_competencia', 'ratio_precio',\n",
       "       'nombre_h_Adidas Own The Run Jacket', 'nombre_h_Adidas Ultraboost 23',\n",
       "       'nombre_h_Asics Gel Nimbus 25', 'nombre_h_Bowflex SelectTech 552',\n",
       "       'nombre_h_Columbia Silver Ridge',\n",
       "       'nombre_h_Decathlon Bandas Elásticas Set', 'nombre_h_Domyos BM900',\n",
       "       'nombre_h_Domyos Kit Mancuernas 20kg',\n",
       "       'nombre_h_Gaiam Premium Yoga Block', 'nombre_h_Liforme Yoga Pad',\n",
       "       'nombre_h_Lotuscrafts Yoga Bolster', 'nombre_h_Manduka PRO Yoga Mat',\n",
       "       'nombre_h_Merrell Moab 2 GTX',\n",
       "       'nombre_h_New Balance Fresh Foam X 1080v12',\n",
       "       'nombre_h_Nike Air Zoom Pegasus 40', 'nombre_h_Nike Dri-FIT Miler',\n",
       "       'nombre_h_Puma Velocity Nitro 2', 'nombre_h_Quechua MH500',\n",
       "       'nombre_h_Reebok Floatride Energy 5',\n",
       "       'nombre_h_Reebok Professional Deck',\n",
       "       'nombre_h_Salomon Speedcross 5 GTX', 'nombre_h_Sveltus Kettlebell 12kg',\n",
       "       'nombre_h_The North Face Borealis', 'nombre_h_Trek Marlin 7',\n",
       "       'categoria_h_Fitness', 'categoria_h_Outdoor', 'categoria_h_Running',\n",
       "       'categoria_h_Wellness', 'subcategoria_h_Banco Gimnasio',\n",
       "       'subcategoria_h_Bandas Elásticas', 'subcategoria_h_Bicicleta Montaña',\n",
       "       'subcategoria_h_Bloque Yoga', 'subcategoria_h_Cojín Yoga',\n",
       "       'subcategoria_h_Esterilla Fitness', 'subcategoria_h_Esterilla Yoga',\n",
       "       'subcategoria_h_Mancuernas Ajustables',\n",
       "       'subcategoria_h_Mochila Trekking', 'subcategoria_h_Pesa Rusa',\n",
       "       'subcategoria_h_Pesas Casa', 'subcategoria_h_Rodillera Yoga',\n",
       "       'subcategoria_h_Ropa Montaña', 'subcategoria_h_Ropa Running',\n",
       "       'subcategoria_h_Zapatillas Running', 'subcategoria_h_Zapatillas Trail'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferencia_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
